{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75056ea8",
   "metadata": {},
   "source": [
    "The following libraries were used to process the videos and generate full feature outputs. In this code, we only select and use the features relevant to our analysis from their generated results.\n",
    "\n",
    "1. Openface: frame, timestamp, gaze_angle_x, gaze_angle_y, pose_Rx(pitch_openface), pose_Ry(yaw_openface), pose_Rz(roll_openface), AU12_c\n",
    "2. PyAFAR: frame, Pitch(pitch_pyafar), Yaw(yaw_pyafar), Roll(roll_pyafar), Occ_au_12(smile_pyafar_pre), Occ_au_4, Occ_au_6\n",
    "3. Rehg: frame, eye-contact-score(gaze_pyafar_pre)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83b6159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\")) \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from scripts.get_paths import get_path\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3796598",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = get_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f682fd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "GT_no_label = pd.read_excel(Path(paths.processed / \"annotations_FD_V2.xlsx\"))\n",
    "participants = GT_no_label['video_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954b97fd",
   "metadata": {},
   "source": [
    "#### For features extacted from libraries - select relevant features and merge into one csv file "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3ed804",
   "metadata": {},
   "source": [
    "## [PyAFAR](https://github.com/AffectAnalysisGroup/PyAFAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6d2ed6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 256,080 | Files merged: 231\n"
     ]
    }
   ],
   "source": [
    "# ---------- CONFIG ----------\n",
    "folder = Path(paths.features_2 / \"pyafar_infant_features\")   \n",
    "out_csv = Path(paths.features_2 / \"pyafar_infant_features_merged.csv\")\n",
    "\n",
    "wanted_cols = [\"Frame\", \"Pitch\", \"Yaw\", \"Roll\", \"Occ_au_12\", \"Occ_au_4\",\"Occ_au_6\"]\n",
    "clip_min, clip_max = 0, 6\n",
    "# ---------------------------\n",
    "\n",
    "pattern = re.compile(r\"^(?P<pid>\\d+)_video_(?P<clip>\\d+)\\.csv$\")\n",
    "\n",
    "all_rows = []\n",
    "skipped = []\n",
    "\n",
    "for fp in folder.glob(\"*.csv\"):\n",
    "    m = pattern.match(fp.name)\n",
    "    if not m:\n",
    "        continue\n",
    "\n",
    "    pid = int(m.group(\"pid\"))\n",
    "    clip = int(m.group(\"clip\"))\n",
    "\n",
    "    if pid not in participants:\n",
    "        continue\n",
    "    if not (clip_min <= clip <= clip_max):\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(fp)\n",
    "    except Exception as e:\n",
    "        skipped.append((fp.name, f\"read_error: {e}\"))\n",
    "        continue\n",
    "\n",
    "    # select only columns that exist\n",
    "    available = [c for c in wanted_cols if c in df.columns]\n",
    "    missing = [c for c in wanted_cols if c not in df.columns]\n",
    "\n",
    "    if not available:\n",
    "        skipped.append((fp.name, f\"no wanted cols found. missing={missing}\"))\n",
    "        continue\n",
    "\n",
    "    df = df[available].copy()\n",
    "    df[\"participant_id\"] = pid\n",
    "    df[\"clip\"] = clip\n",
    "\n",
    "    # optional: keep column order consistent\n",
    "    final_cols = available + [\"participant_id\", \"clip\"]\n",
    "    df = df[final_cols]\n",
    "\n",
    "    all_rows.append(df)\n",
    "\n",
    "if not all_rows:\n",
    "    raise RuntimeError(\"No matching files/rows found. Check folder, participants list, and clip range.\")\n",
    "\n",
    "merged = pd.concat(all_rows, ignore_index=True)\n",
    "\n",
    "# optional: sort\n",
    "merged = merged.sort_values([\"participant_id\", \"clip\"] + ([\"Frame\"] if \"Frame\" in merged.columns else []),\n",
    "                            kind=\"stable\")\n",
    "\n",
    "merged.to_csv(out_csv, index=False)\n",
    "\n",
    "print(f\"Rows: {len(merged):,} | Files merged: {len(all_rows)}\")\n",
    "if skipped:\n",
    "    print(\"\\nSkipped files (first 20):\")\n",
    "    for name, reason in skipped[:20]:\n",
    "        print(f\"  - {name}: {reason}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07af3675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['frame', 'pitch_pyafar', 'yaw_pyafar', 'roll_pyafar',\n",
       "       'smile_pyafar_pre', 'Occ_au_4', 'Occ_au_6', 'participant_id', 'clip'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_pyafar = pd.read_csv(out_csv, index_col=False)\n",
    "merged_pyafar[\"Frame\"] = merged_pyafar[\"Frame\"] + 1 # pyafar starts at 0, but we want to start at 1 to match OpenFace\n",
    "merged_pyafar = merged_pyafar.rename(columns={\n",
    "    \"Frame\":\"frame\",\n",
    "    \"Pitch\": \"pitch_pyafar\",\n",
    "    \"Yaw\": \"yaw_pyafar\",\n",
    "    \"Roll\": \"roll_pyafar\",\n",
    "    \"Occ_au_12\": \"smile_pyafar_pre\" # 'pre' because pyafar returns likelihood of AU being present, which we convert later to binary using a finetuned threshold\n",
    "})\n",
    "merged_pyafar.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc08beec",
   "metadata": {},
   "source": [
    "## [OpenFace](https://github.com/TadasBaltrusaitis/OpenFace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c625eb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 255,976 | Files merged: 231\n"
     ]
    }
   ],
   "source": [
    "# ---------- CONFIG ----------\n",
    "folder = Path(paths.features_1 / \"open_face_features\")  \n",
    "out_csv = Path(paths.features_2 / \"openface_features_merged.csv\")\n",
    "\n",
    "wanted_cols = [\"frame\", \"timestamp\", \"confidence\", \"gaze_angle_x\", \"gaze_angle_y\", \"pose_Rx\", \"pose_Ry\", \"pose_Rz\", \"AU12_c\",\"AU12_r\"]\n",
    "clip_min, clip_max = 0, 6\n",
    "# ---------------------------\n",
    "\n",
    "pattern = re.compile(r\"^(?P<pid>\\d+)_video_(?P<clip>\\d+)\\.csv$\")\n",
    "\n",
    "all_rows = []\n",
    "skipped = []\n",
    "\n",
    "for fp in folder.glob(\"*.csv\"):\n",
    "    m = pattern.match(fp.name)\n",
    "    if not m:\n",
    "        continue\n",
    "\n",
    "    pid = int(m.group(\"pid\"))\n",
    "    clip = int(m.group(\"clip\"))\n",
    "\n",
    "    if pid not in participants:\n",
    "        continue\n",
    "    if not (clip_min <= clip <= clip_max):\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(fp)\n",
    "    except Exception as e:\n",
    "        skipped.append((fp.name, f\"read_error: {e}\"))\n",
    "        continue\n",
    "\n",
    "    # select only columns that exist\n",
    "    available = [c for c in wanted_cols if c in df.columns]\n",
    "    missing = [c for c in wanted_cols if c not in df.columns]\n",
    "\n",
    "    if not available:\n",
    "        skipped.append((fp.name, f\"no wanted cols found. missing={missing}\"))\n",
    "        continue\n",
    "\n",
    "    df = df[available].copy()\n",
    "    df[\"participant_id\"] = pid\n",
    "    df[\"clip\"] = clip\n",
    "\n",
    "    # optional: keep column order consistent\n",
    "    final_cols = available + [\"participant_id\", \"clip\"]\n",
    "    df = df[final_cols]\n",
    "\n",
    "    all_rows.append(df)\n",
    "\n",
    "if not all_rows:\n",
    "    raise RuntimeError(\"No matching files/rows found. Check folder, participants list, and clip range.\")\n",
    "\n",
    "merged = pd.concat(all_rows, ignore_index=True)\n",
    "\n",
    "# optional: sort\n",
    "merged = merged.sort_values([\"participant_id\", \"clip\"] + ([\"Frame\"] if \"Frame\" in merged.columns else []),\n",
    "                            kind=\"stable\")\n",
    "\n",
    "merged.to_csv(out_csv, index=False)\n",
    "\n",
    "print(f\"Rows: {len(merged):,} | Files merged: {len(all_rows)}\")\n",
    "if skipped:\n",
    "    print(\"\\nSkipped files (first 20):\")\n",
    "    for name, reason in skipped[:20]:\n",
    "        print(f\"  - {name}: {reason}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "145da064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['frame', 'timestamp', 'confidence', 'gaze_angle_x', 'gaze_angle_y',\n",
       "       'pitch_openface', 'yaw_openface', 'roll_openface', 'smile_openface',\n",
       "       'AU12_r', 'participant_id', 'clip'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_openface = pd.read_csv(out_csv, index_col=False)\n",
    "merged_openface = merged_openface.rename(columns={\n",
    "    \"pose_Rx\": \"pitch_openface\",\n",
    "    \"pose_Ry\": \"yaw_openface\",\n",
    "    \"pose_Rz\": \"roll_openface\",\n",
    "    \"AU12_c\": \"smile_openface\"\n",
    "})\n",
    "merged_openface.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6feffa47",
   "metadata": {},
   "source": [
    "## [Rehg eye gaze library](https://github.com/rehg-lab/eye-contact-cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5ec93a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 256,079 | Files merged: 231\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------- CONFIG ----------\n",
    "folder = Path(paths.features_2 / \"gaze_rehg_features\")   \n",
    "out_csv = Path(paths.features_2 / \"rehg_eye_contact_merged.csv\")\n",
    "\n",
    "clip_min, clip_max = 0, 6\n",
    "# ---------------------------\n",
    "\n",
    "pattern = re.compile(r\"^(?P<pid>\\d+)_video_(?P<clip>\\d+)_output\\.txt$\")\n",
    "\n",
    "all_rows = []\n",
    "skipped = []\n",
    "\n",
    "for fp in folder.glob(\"*.txt\"):\n",
    "    m = pattern.match(fp.name)\n",
    "    if not m:\n",
    "        continue\n",
    "\n",
    "    pid = int(m.group(\"pid\"))\n",
    "    clip = int(m.group(\"clip\"))\n",
    "\n",
    "    if pid not in participants:\n",
    "        continue\n",
    "    if not (clip_min <= clip <= clip_max):\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Files look like: \"1,0.939229\" (no header)\n",
    "        df = pd.read_csv(fp, header=None, names=[\"Frame\", \"eye-contact-score\"])\n",
    "    except Exception as e:\n",
    "        skipped.append((fp.name, f\"read_error: {e}\"))\n",
    "        continue\n",
    "\n",
    "    # Basic cleanup: drop empty/NaN lines, coerce types\n",
    "    df = df.dropna(how=\"any\")\n",
    "    df[\"Frame\"] = pd.to_numeric(df[\"Frame\"], errors=\"coerce\")\n",
    "    df[\"eye-contact-score\"] = pd.to_numeric(df[\"eye-contact-score\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"Frame\", \"eye-contact-score\"])\n",
    "\n",
    "    df[\"participant_id\"] = pid\n",
    "    df[\"clip\"] = clip\n",
    "\n",
    "    df = df[[\"Frame\", \"eye-contact-score\", \"participant_id\", \"clip\"]]\n",
    "    all_rows.append(df)\n",
    "\n",
    "if not all_rows:\n",
    "    raise RuntimeError(\"No matching files/rows found. Check folder, participants list, and clip range.\")\n",
    "\n",
    "merged = pd.concat(all_rows, ignore_index=True)\n",
    "merged = merged.sort_values([\"participant_id\", \"clip\", \"Frame\"], kind=\"stable\")\n",
    "\n",
    "merged.to_csv(out_csv, index=False)\n",
    "\n",
    "print(f\"Rows: {len(merged):,} | Files merged: {len(all_rows)}\")\n",
    "if skipped:\n",
    "    print(\"\\nSkipped files (first 20):\")\n",
    "    for name, reason in skipped[:20]:\n",
    "        print(f\"  - {name}: {reason}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b9ca061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['frame', 'gaze_pyafar_pre', 'participant_id', 'clip'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_rehg = pd.read_csv(out_csv, index_col=False)\n",
    "merged_rehg = merged_rehg.rename(columns={\n",
    "    \"Frame\": \"frame\",\n",
    "    \"eye-contact-score\": \"gaze_pyafar_pre\" # 'pre' because we will convert this to binary using a finetuned threshold later\n",
    "})\n",
    "merged_rehg.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5505548",
   "metadata": {},
   "source": [
    "## Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc14d57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYS = [\"participant_id\", \"clip\", \"frame\"]\n",
    "\n",
    "def mismatch_report(a, b, a_name, b_name):\n",
    "    a_keys = a[KEYS].drop_duplicates()\n",
    "    b_keys = b[KEYS].drop_duplicates()\n",
    "\n",
    "    ab = a_keys.merge(b_keys, on=KEYS, how=\"outer\", indicator=True)\n",
    "\n",
    "    only_a = ab[ab[\"_merge\"] == \"left_only\"].drop(columns=\"_merge\")\n",
    "    only_b = ab[ab[\"_merge\"] == \"right_only\"].drop(columns=\"_merge\")\n",
    "\n",
    "    # Summaries per participant_id+clip\n",
    "    only_a_sum = (only_a.groupby([\"participant_id\", \"clip\"])[\"frame\"]\n",
    "                  .agg(n_missing=f\"count\", min_frame=\"min\", max_frame=\"max\")\n",
    "                  .reset_index()\n",
    "                  .sort_values([\"participant_id\", \"clip\"]))\n",
    "    only_b_sum = (only_b.groupby([\"participant_id\", \"clip\"])[\"frame\"]\n",
    "                  .agg(n_missing=f\"count\", min_frame=\"min\", max_frame=\"max\")\n",
    "                  .reset_index()\n",
    "                  .sort_values([\"participant_id\", \"clip\"]))\n",
    "\n",
    "    #print(f\"\\n=== Frames present in {a_name} but missing in {b_name} ===\")\n",
    "    # if only_a.empty:\n",
    "    #     print(\"None ✅\")\n",
    "    # else:\n",
    "    #     print(only_a_sum.to_string(index=False))\n",
    "\n",
    "    # print(f\"\\n=== Frames present in {b_name} but missing in {a_name} ===\")\n",
    "    # if only_b.empty:\n",
    "    #     print(\"None ✅\")\n",
    "    # else:\n",
    "    #     print(only_b_sum.to_string(index=False))\n",
    "\n",
    "    return only_a, only_b\n",
    "\n",
    "# Pairwise mismatch reporting (you can comment any out)\n",
    "missing_pyafar_vs_openface, missing_openface_vs_pyafar = mismatch_report(\n",
    "    merged_pyafar, merged_openface, \"pyafar\", \"openface\"\n",
    ")\n",
    "missing_pyafar_vs_rehg, missing_rehg_vs_pyafar = mismatch_report(\n",
    "    merged_pyafar, merged_rehg, \"pyafar\", \"rehg\"\n",
    ")\n",
    "missing_openface_vs_rehg, missing_rehg_vs_openface = mismatch_report(\n",
    "    merged_openface, merged_rehg, \"openface\", \"rehg\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba27d025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged (inner, fully aligned) rows: 255975\n"
     ]
    }
   ],
   "source": [
    "merged_inner = (\n",
    "    merged_pyafar\n",
    "      .merge(merged_openface, on=KEYS, how=\"inner\")\n",
    "      .merge(merged_rehg,     on=KEYS, how=\"inner\")\n",
    ")\n",
    "\n",
    "print(\"Merged (inner, fully aligned) rows:\", len(merged_inner))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3306abfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_inner.to_csv(paths.features_2 / \"extracted_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ef54a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c39651",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyafar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
